# =====================================================
# ç»Ÿä¸€è®­ç»ƒé…ç½®æ–‡ä»¶ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
# =====================================================

# åŸºæœ¬é…ç½®
exp_name: refactored_experiment
split_seed: 42
seed: 42

# æ•°æ®é…ç½®
data:
  data_dir: ADvsCN.ex001_2_p288
  data_name: ADvsCN.ex001_2_p288_pw24_all
  patch_size: 24
  num_folds: 5

# ç¼“å­˜ç®¡ç†é…ç½®
cache:
  base_dir: ./cache
  auto_clean: false

# DenseNeté¢„è®­ç»ƒé…ç½®
densenet:
  pretrain:
    num_epochs: 70
    batch_size: 48        # ğŸ”§ å¢åŠ æ‰¹æ¬¡å¤§å° (æ¯GPU 16ä¸ª)
    learning_rate: 0.0005
    weight_decay: 0.0001
    num_workers: 16       # ğŸ”§ å¢åŠ æ•°æ®åŠ è½½çº¿ç¨‹ (4å€GPUæ•°)
    patience: 40
  model:
    growth_rate: 8
    num_init_features: 24

# å›¾è¾¹æ„å»ºé…ç½®
graph:
  build:
    k_neighbors: 20              
    frequency_threshold: 0.3
    similarity_threshold: 0.7  # åŒé‡ç­›é€‰
    similarity_metric: cosine
    batch_size: 64
    use_all_data: true
  params:
    node_type: px
    edge_type: abscorr
    dist_type: euc_1+gau
    adj_norm: DAD

# ä¸»è®­ç»ƒé…ç½®
train:
  folds: [0, 1, 2, 3, 4]
  pre_epoch: 30
  num_epoch: 110
  stage_transition_epoch: 70
  batch_size: 72          # ğŸ”§ å¢åŠ æ‰¹æ¬¡å¤§å° (æ¯GPU 24ä¸ª)
  test_batch_size: 66
  
  # ä¼˜åŒ–å™¨
  optimizer: SGD
  base_lr: 0.0003
  base_lr_mask: 4
  weight_decay_adamw: 0.01
  weight_decay: 0.0005
  nesterov: true
  scheduler: auto
  stepsize: 30
  gamma: 0.7
  
  # ç¨€ç–åº¦æ­£åˆ™åŒ–é¢„çƒ­ï¼ˆæ–°å¢ï¼‰
  loss_weights:
    L_inv: 0
    L_sen: 0.5
    L_pred: 1
    L_spu: 1
    lambda_l1: 0
    lambda_sparsity: 0.2
    lambda_edge_multiplier: 6.0  # æ–°å¢è¿™ä¸€è¡Œ

  sparsity_warmup_epochs: 15

# æ¨¡å‹é…ç½®
model:
  name: net.networks
  args:
    hidden1: [28]
    kernels: [2]
    hidden2: [28, 28]
    freeze_extractor: true

# å…¶ä»–é…ç½®
misc:
  device: [0, 1, 2]
  gumble_tau: 1
  log_interval: 100
  save_interval: 5
  eval_interval: 5
  print_log: true